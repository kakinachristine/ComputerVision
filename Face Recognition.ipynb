{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FACE RECOGNITION",
   "id": "9a29ef1403d83e25"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:29:01.535863Z",
     "start_time": "2025-07-30T13:29:01.517920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importing the libraries\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import os\n"
   ],
   "id": "8684af1167d5d99f",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:29:02.267932Z",
     "start_time": "2025-07-30T13:29:01.643554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "# load the saved model\n",
    "model = load_model('vgg16_fr.h5')\n",
    "\n",
    "# Loading the cascades\n",
    "face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ],
   "id": "dc82a16f27beb6f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:29:03.725087Z",
     "start_time": "2025-07-30T13:29:02.311238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test\n",
    "test_image = cv2.imread('.\\\\Datasets\\\\Test\\\\richa\\\\richa-1.jpg')\n",
    "face_portion=face_detector.detectMultiScale(test_image) # Detect faces in the test image\n",
    "\n",
    "# Check if no faces are detected in the test image\n",
    "if face_portion is ():\n",
    "    print(\"Face is not found\")\n",
    "\n",
    "# If faces are detected, process each face in the face_portion list\n",
    "else:\n",
    "    for (x,y,w,h) in face_portion:\n",
    "        x=x-30\n",
    "        y=y-30\n",
    "        cropped_image=test_image[y:y+h+30,x:x+w+30]\n",
    "    if type(cropped_image) is np.ndarray:\n",
    "        img_array = cv2.resize(cropped_image, (224, 224))\n",
    "        # convert a NumPy array (which is typically how images are represented in libraries like OpenCV)\n",
    "        # into a PIL (Python Imaging Library) Image object\n",
    "        #im = Image.fromarray(cropped_image, 'RGB')\n",
    "        #Resizing into 224x224 because we trained the model with this image size.\n",
    "        #img_array = np.array(im)\n",
    "        #Our keras model used a 4D tensor, (images x height x width x channel)\n",
    "        #So changing dimension 224x224x3 into 1x224x224x3\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        pred = model.predict(img_array)\n",
    "        print(pred)\n",
    "\n",
    "\n",
    "\n",
    "        if(pred[0][0]>0.7):\n",
    "            name='Nilay'\n",
    "        elif(pred[0][1]>0.7):\n",
    "            name='Richa'\n",
    "        elif(pred[0][2]>0.7):\n",
    "            name = 'Trevor'\n",
    "        else:\n",
    "            name=\"None matching\"\n"
   ],
   "id": "17b187b0665a17e5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\ChristineKakina\\AppData\\Local\\Temp\\ipykernel_34704\\3766421245.py:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if face_portion is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1s/step\n",
      "[[0. 1. 0.]]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:29:03.798318Z",
     "start_time": "2025-07-30T13:29:03.778300Z"
    }
   },
   "cell_type": "code",
   "source": "print(name)\n",
   "id": "c866ae8f9387f8d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Richa\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:29:03.930212Z",
     "start_time": "2025-07-30T13:29:03.919804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Directory containing the subfolders, each representing a class\n",
    "directory = 'Datasets/Train'\n",
    "\n",
    "# Get a list of all subfolders (class names) in the directory\n",
    "classNames = [f.name for f in os.scandir(directory) if f.is_dir()]\n",
    "\n",
    "# Print the class names\n",
    "print(classNames)"
   ],
   "id": "bdfc8fbe0e8a1d43",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nilay', 'richa', 'trevor']\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
